{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import warnings\n",
    "from typing import *\n",
    "import traceback\n",
    "\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from transformers import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from medmax.agent import *\n",
    "from medmax.tools import *\n",
    "from medmax.utils import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.set_verbosity_error()\n",
    "_ = load_dotenv()\n",
    "\n",
    "PROMPT_FILE = \"medmax/docs/system_prompts.txt\"\n",
    "\n",
    "\"\"\"\n",
    "0. Fix gradio issues and image visualizition tools\n",
    "1. New tool: https://www.nature.com/articles/s41551-024-01246-y\n",
    "2. New tool: https://huggingface.co/microsoft/maira-2\n",
    "3. Change the LLM to public LLM\n",
    "4. Explore code generation\n",
    "5. SFT or example database, prompt enhancing to make tool call better\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_tool = ChestXRayReportGeneratorTool()\n",
    "xray_classification_tool = ChestXRayClassifierTool()\n",
    "medical_visual_qa_tool = MedicalVisualQATool()\n",
    "segmentation_tool = ChestXRaySegmentationTool()\n",
    "image_visualizer_tool = ImageVisualizerTool()\n",
    "\n",
    "print(f\"Type: {type(report_tool)}, Name: {report_tool.name}\")\n",
    "print(f\"Type: {type(xray_classification_tool)}, Name: {xray_classification_tool.name}\")\n",
    "print(f\"Type: {type(medical_visual_qa_tool)}, Name: {medical_visual_qa_tool.name}\")\n",
    "print(f\"Type: {type(segmentation_tool)}, Name: {segmentation_tool.name}\")\n",
    "print(f\"Type: {type(image_visualizer_tool)}, Name: {image_visualizer_tool.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = load_prompts_from_file(PROMPT_FILE)\n",
    "prompt = prompts[\"MEDICAL_ASSISTANT\"]\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "model = ChatOpenAI(model=\"gpt-4o-2024-08-06\", temperature=0, top_p=0.95)\n",
    "agent = Agent(\n",
    "    model, \n",
    "    tools=[xray_classification_tool, medical_visual_qa_tool, report_tool, segmentation_tool],\n",
    "    log_tools=True,\n",
    "    log_dir=\"logs\",\n",
    "    system_prompt=prompt, \n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Image(agent.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [HumanMessage(content=\"Does the image `demo/chest/pneumonia4.jpg` show pneumonia?\")]\n",
    "# messages = [HumanMessage(content=\"Provide a radiology report for the given image `demo/chest/pneumonia2.jpg`.\")]\n",
    "# messages = [HumanMessage(content=\"Descibe the given image.\")]\n",
    "# messages = [HumanMessage(content=\"What was the first question I asked?\")]\n",
    "# messages = [HumanMessage(content=\"What is the probability of pneumonia in the image `demo/chest/normal1.jpg`?\")]\n",
    "# messages = [HumanMessage(content=\"Does the patient with chest xray given here need to go see doctor? `demo/chest/normal1.jpg`\")]\n",
    "# messages = [HumanMessage(content=\"What is the size of heart?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for event in agent.workflow.stream({\"messages\": messages}, thread):\n",
    "#     for v in event.values():\n",
    "#         print(v, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "import time\n",
    "import shutil\n",
    "from typing import List, Optional\n",
    "from gradio import ChatMessage\n",
    "\n",
    "class ChatInterface:\n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "        self.upload_dir = Path(\"temp\")\n",
    "        self.upload_dir.mkdir(exist_ok=True)\n",
    "        self.current_thread_id = None\n",
    "        \n",
    "    def handle_upload(self, image_path: str) -> str:\n",
    "        \"\"\"Handle image upload and return the new path\"\"\"\n",
    "        if not image_path:\n",
    "            return None\n",
    "            \n",
    "        source = Path(image_path)\n",
    "        dest = self.upload_dir / f\"upload_{int(time.time())}{source.suffix}\"\n",
    "        shutil.copy2(source, dest)\n",
    "        return str(dest)\n",
    "\n",
    "    async def process_message(self, \n",
    "                            message: str, \n",
    "                            image: Optional[str], \n",
    "                            chat_history: List[ChatMessage]) -> List[ChatMessage]:\n",
    "        chat_history = chat_history or []\n",
    "        \n",
    "        # Handle image if present\n",
    "        if image:\n",
    "            saved_image = self.handle_upload(image)\n",
    "            message = f\"{message} `{saved_image}`\"\n",
    "        \n",
    "        # Initialize thread ID if needed\n",
    "        if not self.current_thread_id:\n",
    "            self.current_thread_id = str(time.time())\n",
    "        \n",
    "        # Add user message to history\n",
    "        chat_history.append(ChatMessage(role=\"user\", content=message))\n",
    "        yield chat_history\n",
    "        \n",
    "        try:\n",
    "            # Process through your agent's workflow\n",
    "            for event in self.agent.workflow.stream(\n",
    "                {\"messages\": [{\"role\": \"user\", \"content\": message}]},\n",
    "                {\"configurable\": {\"thread_id\": self.current_thread_id}}\n",
    "            ):\n",
    "                if isinstance(event, dict):\n",
    "                    if 'process' in event:\n",
    "                        # Handle main response\n",
    "                        content = event['process']['messages'][-1].content\n",
    "                        if content:\n",
    "                            chat_history.append(ChatMessage(\n",
    "                                role=\"assistant\",\n",
    "                                content=content\n",
    "                            ))\n",
    "                            yield chat_history\n",
    "                    elif 'execute' in event:\n",
    "                        # Handle tool execution\n",
    "                        tool_name = event['execute']['messages'][-1].name\n",
    "                        tool_result = eval(event['execute']['messages'][-1].content)[0]\n",
    "                        if tool_result:\n",
    "                            formatted_result = '\\n'.join(line.strip() for line in str(tool_result).splitlines())\n",
    "                            chat_history.append(ChatMessage(\n",
    "                                role=\"assistant\",\n",
    "                                content=formatted_result,\n",
    "                                metadata={\"title\": f\"üîß Using tool: {tool_name}\"},\n",
    "                            ))\n",
    "                            yield chat_history\n",
    "                            \n",
    "        except Exception as e:\n",
    "            chat_history.append(ChatMessage(\n",
    "                role=\"assistant\",\n",
    "                content=f\"‚ùå Error: {str(e)}\",\n",
    "                metadata={\"title\": \"Error\"}\n",
    "            ))\n",
    "            yield chat_history\n",
    "\n",
    "def create_demo(agent):\n",
    "    interface = ChatInterface(agent)\n",
    "    \n",
    "    with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"\"\"\n",
    "            # üè• MedMAX\n",
    "            Multimodal Medical Agent for Chest X-rays\n",
    "            \"\"\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=3):\n",
    "                    chatbot = gr.Chatbot(\n",
    "                        [],\n",
    "                        height=900,\n",
    "                        container=True,\n",
    "                        show_label=True,\n",
    "                        elem_classes=\"chat-box\",\n",
    "                        type=\"messages\",\n",
    "                        label=\"Agent\",\n",
    "                        avatar_images=(None, \"https://em-content.zobj.net/source/twitter/53/robot-face_1f916.png\")\n",
    "                    )\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=3):\n",
    "                            txt = gr.Textbox(\n",
    "                                show_label=False,\n",
    "                                placeholder=\"Ask about the X-ray...\",\n",
    "                                container=False\n",
    "                            )\n",
    "                            \n",
    "                with gr.Column(scale=2):\n",
    "                    image_display = gr.Image(\n",
    "                        label=\"Current X-Ray\",\n",
    "                        type=\"filepath\",\n",
    "                        height=600,\n",
    "                        container=True\n",
    "                    )\n",
    "                    upload_button = gr.UploadButton(\n",
    "                        \"üìé Upload X-Ray\",\n",
    "                        file_types=[\"image\"],\n",
    "                    )\n",
    "                    with gr.Row():\n",
    "                        clear_btn = gr.Button(\"Clear Chat\")\n",
    "                        new_thread_btn = gr.Button(\"New Thread\")\n",
    "\n",
    "        # Event handlers\n",
    "        def clear_chat():\n",
    "            return [], None\n",
    "\n",
    "        def new_thread():\n",
    "            interface.current_thread_id = str(time.time())\n",
    "            return [], None\n",
    "\n",
    "        txt.submit(\n",
    "            interface.process_message,\n",
    "            inputs=[txt, image_display, chatbot],\n",
    "            outputs=chatbot\n",
    "        ).then(\n",
    "            lambda: (\"\", None),\n",
    "            None,\n",
    "            [txt, image_display]\n",
    "        )\n",
    "\n",
    "        upload_button.upload(\n",
    "            lambda x: x,\n",
    "            inputs=upload_button,\n",
    "            outputs=image_display\n",
    "        )\n",
    "\n",
    "        clear_btn.click(clear_chat, outputs=[chatbot, image_display])\n",
    "        new_thread_btn.click(new_thread, outputs=[chatbot, image_display])\n",
    "\n",
    "    return demo\n",
    "\n",
    "demo = create_demo(agent)\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
