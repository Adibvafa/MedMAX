{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import warnings\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from transformers import logging\n",
    "\n",
    "from medixar.agent import *\n",
    "from medixar.tools import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.set_verbosity_error()\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_tool = RadiologyReportGeneratorTool()\n",
    "organ_size_tool = OrganSizeMeasurementTool()\n",
    "\n",
    "print(type(report_tool))\n",
    "print(report_tool.name)\n",
    "print(type(organ_size_tool))\n",
    "print(organ_size_tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart medical assistant. Use the tools available to answer questions. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "Do not use formatting in your response.\n",
    "\"\"\"\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "model = ChatOpenAI(model=\"gpt-4o-2024-08-06\")\n",
    "agent = Agent(model, [report_tool, organ_size_tool], system=prompt, checkpointer=checkpointer)\n",
    "\n",
    "Image(agent.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "messages = [HumanMessage(content=\"What is the report of the radiology image `image.png`\")]\n",
    "\n",
    "for event in agent.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the volume of the heart (mL)?\")]\n",
    "\n",
    "for event in agent.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What was the question I asked you?\")]\n",
    "\n",
    "for event in agent.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################# LEGACY CODE #############################################################\n",
    "# web_search_tool = WebSearchTool()\n",
    "\n",
    "# agent = Agent(\n",
    "#     model=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "#     tools={\"web_search\": web_search_tool},\n",
    "#     tools_json_path=\"medixar/docs/tools.json\",\n",
    "#     system_prompts_file=\"medixar/docs/system_prompts.txt\",\n",
    "#     system_prompt_type=\"MEDICAL_ASSISTANT\",\n",
    "#     device=\"auto\",\n",
    "#     torch_dtype=torch.float16,\n",
    "#     max_new_tokens=250,\n",
    "#     temperature=0.7,\n",
    "#     top_p=0.95\n",
    "# )\n",
    "\n",
    "# response = agent.generate(\"What is all you need? Respond using web search tool.\")\n",
    "# agent.messages\n",
    "# agent.generate(\"what was the answer to what is all you need?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "light",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
