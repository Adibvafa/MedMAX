{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import warnings\n",
    "from typing import *\n",
    "import traceback\n",
    "\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from transformers import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from medmax.agent import *\n",
    "from medmax.tools import *\n",
    "from medmax.utils import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.set_verbosity_error()\n",
    "_ = load_dotenv()\n",
    "\n",
    "PROMPT_FILE = \"medmax/docs/system_prompts.txt\"\n",
    "\n",
    "\"\"\"\n",
    "0. Fix gradio issues and image visualizition tools\n",
    "1. New tool: https://www.nature.com/articles/s41551-024-01246-y\n",
    "2. New tool: https://huggingface.co/microsoft/maira-2\n",
    "3. Change the LLM to public LLM\n",
    "4. Explore code generation\n",
    "5. SFT or example database, prompt enhancing to make tool call better\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type, Dict, Tuple\n",
    "from pydantic import BaseModel, Field\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_core.callbacks import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")\n",
    "from langchain_core.tools import BaseTool\n",
    "\n",
    "\n",
    "class ImageVisualizerInput(BaseModel):\n",
    "    \"\"\"Input schema for the Image Visualizer Tool.\"\"\"\n",
    "\n",
    "    image_path: str = Field(..., description=\"Path to the image file to display\")\n",
    "    title: Optional[str] = Field(None, description=\"Optional title to display above the image\")\n",
    "    description: Optional[str] = Field(\n",
    "        None, description=\"Optional description to display below the image\"\n",
    "    )\n",
    "    figsize: Optional[tuple] = Field(\n",
    "        (10, 10), description=\"Optional figure size as (width, height) in inches\"\n",
    "    )\n",
    "    cmap: Optional[str] = Field(\n",
    "        \"rgb\", description=\"Optional colormap to use for displaying the image\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ImageVisualizerTool(BaseTool):\n",
    "    \"\"\"Tool for displaying medical images to users with annotations.\"\"\"\n",
    "\n",
    "    name: str = \"image_visualizer\"\n",
    "    description: str = (\n",
    "        \"Displays images to users with optional titles and descriptions. \"\n",
    "        \"Input: Path to image file and optional display parameters. \"\n",
    "        \"Output: Dict with image path and metadata.\"\n",
    "    )\n",
    "    args_schema: Type[BaseModel] = ImageVisualizerInput\n",
    "\n",
    "    def _display_image(\n",
    "        self,\n",
    "        image_path: str,\n",
    "        title: Optional[str] = None,\n",
    "        description: Optional[str] = None,\n",
    "        figsize: tuple = (10, 10),\n",
    "        cmap: str = \"rgb\",\n",
    "    ) -> None:\n",
    "        \"\"\"Display an image with optional annotations.\"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        img = skimage.io.imread(image_path)\n",
    "        if len(img.shape) > 2 and cmap != \"rgb\":\n",
    "            img = img[..., 0]\n",
    "\n",
    "        plt.imshow(img, cmap=None if cmap == \"rgb\" else cmap)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        if title:\n",
    "            plt.title(title, pad=15, fontsize=12)\n",
    "\n",
    "        # Add description if provided\n",
    "        if description:\n",
    "            plt.figtext(\n",
    "                0.5, 0.01, description, wrap=True, horizontalalignment=\"center\", fontsize=10\n",
    "            )\n",
    "\n",
    "        # Adjust margins to minimize whitespace while preventing overlap\n",
    "        plt.subplots_adjust(top=0.95, bottom=0.05, left=0.05, right=0.95)\n",
    "        plt.show()\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        image_path: str,\n",
    "        title: Optional[str] = None,\n",
    "        description: Optional[str] = None,\n",
    "        figsize: tuple = (10, 10),\n",
    "        cmap: str = \"rgb\",\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> dict:\n",
    "        \"\"\"\n",
    "        Display an image to the user with optional annotations.\n",
    "\n",
    "        Args:\n",
    "            image_path: Path to the image file\n",
    "            title: Optional title to display above image\n",
    "            description: Optional description to display below image\n",
    "            figsize: Optional figure size as (width, height)\n",
    "            cmap: Optional colormap to use for displaying the image\n",
    "            run_manager: Optional callback manager\n",
    "\n",
    "        Returns:\n",
    "            Dict containing display status and metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Verify image path\n",
    "            if not Path(image_path).is_file():\n",
    "                raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "\n",
    "            # Display image\n",
    "            self._display_image(image_path, title, description, figsize, cmap)\n",
    "\n",
    "            output = {\"image_path\": image_path}\n",
    "            metadata = {\n",
    "                \"image_path\": image_path,\n",
    "                \"title\": bool(title),\n",
    "                \"description\": bool(description),\n",
    "                \"figsize\": figsize,\n",
    "                \"cmap\": cmap,\n",
    "                \"analysis_status\": \"completed\",\n",
    "            }\n",
    "            return output, metadata\n",
    "\n",
    "        except Exception as e:\n",
    "            return (\n",
    "                {\"error\": str(e)},\n",
    "                {\n",
    "                    \"image_path\": image_path,\n",
    "                    \"visualization_status\": \"failed\",\n",
    "                    \"note\": \"An error occurred during image visualization\",\n",
    "                },\n",
    "            )\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        image_path: str,\n",
    "        title: Optional[str] = None,\n",
    "        description: Optional[str] = None,\n",
    "        figsize: tuple = (10, 10),\n",
    "        cmap: str = \"rgb\",\n",
    "        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,\n",
    "    ) -> Tuple[Dict[str, any], Dict]:\n",
    "        \"\"\"Async version of _run.\"\"\"\n",
    "        return self._run(image_path, title, description, figsize, cmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report_tool = ChestXRayReportGeneratorTool()\n",
    "# xray_classification_tool = ChestXRayClassifierTool()\n",
    "# medical_visual_qa_tool = MedicalVisualQATool()\n",
    "# segmentation_tool = ChestXRaySegmentationTool()\n",
    "image_visualizer_tool = ImageVisualizerTool()\n",
    "\n",
    "print(f\"Type: {type(report_tool)}, Name: {report_tool.name}\")\n",
    "print(f\"Type: {type(xray_classification_tool)}, Name: {xray_classification_tool.name}\")\n",
    "print(f\"Type: {type(medical_visual_qa_tool)}, Name: {medical_visual_qa_tool.name}\")\n",
    "print(f\"Type: {type(segmentation_tool)}, Name: {segmentation_tool.name}\")\n",
    "print(f\"Type: {type(image_visualizer_tool)}, Name: {image_visualizer_tool.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = load_prompts_from_file(PROMPT_FILE)\n",
    "prompt = prompts[\"MEDICAL_ASSISTANT\"]\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "model = ChatOpenAI(model=\"gpt-4o-2024-08-06\", temperature=0, top_p=0.95)\n",
    "agent = Agent(\n",
    "    model, \n",
    "    tools=[xray_classification_tool, medical_visual_qa_tool, report_tool, segmentation_tool, image_visualizer_tool],\n",
    "    log_tools=True,\n",
    "    log_dir=\"logs\",\n",
    "    system_prompt=prompt, \n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Image(agent.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [HumanMessage(content=\"Does the image `demo/chest/pneumonia4.jpg` show pneumonia?\")]\n",
    "# messages = [HumanMessage(content=\"Provide a radiology report for the given image `demo/chest/pneumonia2.jpg`.\")]\n",
    "# messages = [HumanMessage(content=\"Descibe the given image.\")]\n",
    "# messages = [HumanMessage(content=\"What was the first question I asked?\")]\n",
    "# messages = [HumanMessage(content=\"What is the probability of pneumonia in the image `demo/chest/normal1.jpg`?\")]\n",
    "# messages = [HumanMessage(content=\"Does the patient with chest xray given here need to go see doctor? `demo/chest/normal1.jpg`\")]\n",
    "# messages = [HumanMessage(content=\"What is the size of heart?\")]\n",
    "messages = [HumanMessage(content=\"Use visualizer tool. Display the image `demo/chest/normal1.jpg`.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in agent.workflow.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "import time\n",
    "import shutil\n",
    "from typing import List, Optional\n",
    "from gradio import ChatMessage\n",
    "\n",
    "class ChatInterface:\n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "        self.upload_dir = Path(\"temp\")\n",
    "        self.upload_dir.mkdir(exist_ok=True)\n",
    "        self.current_thread_id = None\n",
    "        \n",
    "    def handle_upload(self, image_path: str) -> str:\n",
    "        \"\"\"Handle image upload and return the new path\"\"\"\n",
    "        if not image_path:\n",
    "            return None\n",
    "            \n",
    "        source = Path(image_path)\n",
    "        dest = self.upload_dir / f\"upload_{int(time.time())}{source.suffix}\"\n",
    "        shutil.copy2(source, dest)\n",
    "        return str(dest)\n",
    "\n",
    "    async def process_message(self, \n",
    "                            message: str, \n",
    "                            image: Optional[str], \n",
    "                            chat_history: List[ChatMessage]) -> List[ChatMessage]:\n",
    "        chat_history = chat_history or []\n",
    "        current_image = image  # Track current image\n",
    "        \n",
    "        if image:\n",
    "            saved_image = self.handle_upload(image)\n",
    "            message = f\"{message} `{saved_image}`\"\n",
    "        \n",
    "        if not self.current_thread_id:\n",
    "            self.current_thread_id = str(time.time())\n",
    "        \n",
    "        chat_history.append(ChatMessage(role=\"user\", content=message))\n",
    "        yield chat_history, current_image  # Initial yield with both values\n",
    "        \n",
    "        try:\n",
    "            for event in self.agent.workflow.stream(\n",
    "                {\"messages\": [{\"role\": \"user\", \"content\": message}]},\n",
    "                {\"configurable\": {\"thread_id\": self.current_thread_id}}\n",
    "            ):\n",
    "                if isinstance(event, dict):\n",
    "                    if 'process' in event:\n",
    "                        content = event['process']['messages'][-1].content\n",
    "                        if content:\n",
    "                            chat_history.append(ChatMessage(\n",
    "                                role=\"assistant\",\n",
    "                                content=content\n",
    "                            ))\n",
    "                            yield chat_history, current_image\n",
    "\n",
    "                    elif 'execute' in event:\n",
    "                        for message in event['execute']['messages']:\n",
    "                            tool_name = message.name\n",
    "                            tool_result = eval(message.content)[0]\n",
    "                            \n",
    "                            if tool_name == \"image_visualizer\":\n",
    "                                current_image = message.args['image_path']\n",
    "                            \n",
    "                            if tool_result:\n",
    "                                formatted_result = ' '.join(line.strip() for line in str(tool_result).splitlines()).strip()\n",
    "                                chat_history.append(ChatMessage(\n",
    "                                    role=\"assistant\",\n",
    "                                    content=formatted_result,\n",
    "                                    metadata={\"title\": f\"üîß Using tool: {tool_name}\"},\n",
    "                                ))\n",
    "                                yield chat_history, current_image\n",
    "                            \n",
    "        except Exception as e:\n",
    "            chat_history.append(ChatMessage(\n",
    "                role=\"assistant\",\n",
    "                content=f\"‚ùå Error: {str(e)}\",\n",
    "                metadata={\"title\": \"Error\"}\n",
    "            ))\n",
    "            yield chat_history, current_image\n",
    "\n",
    "def create_demo(agent):\n",
    "    interface = ChatInterface(agent)\n",
    "    \n",
    "    with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"\"\"\n",
    "            # üè• MedMAX\n",
    "            Multimodal Medical Agent for Chest X-rays\n",
    "            \"\"\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=3):\n",
    "                    chatbot = gr.Chatbot(\n",
    "                        [],\n",
    "                        height=800,\n",
    "                        container=True,\n",
    "                        show_label=True,\n",
    "                        elem_classes=\"chat-box\",\n",
    "                        type=\"messages\",\n",
    "                        label=\"Agent\",\n",
    "                        avatar_images=(None, \"https://em-content.zobj.net/source/twitter/53/robot-face_1f916.png\")\n",
    "                    )\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=3):\n",
    "                            txt = gr.Textbox(\n",
    "                                show_label=False,\n",
    "                                placeholder=\"Ask about the X-ray...\",\n",
    "                                container=False\n",
    "                            )\n",
    "                            \n",
    "                with gr.Column(scale=3):\n",
    "                    image_display = gr.Image(\n",
    "                        label=\"Image\",\n",
    "                        type=\"filepath\",\n",
    "                        height=700,\n",
    "                        container=True\n",
    "                    )\n",
    "                    upload_button = gr.UploadButton(\n",
    "                        \"üìé Upload X-Ray\",\n",
    "                        file_types=[\"image\"],\n",
    "                    )\n",
    "                    with gr.Row():\n",
    "                        clear_btn = gr.Button(\"Clear Chat\")\n",
    "                        new_thread_btn = gr.Button(\"New Thread\")\n",
    "\n",
    "        # Event handlers\n",
    "        def clear_chat():\n",
    "            return [], None\n",
    "\n",
    "        def new_thread():\n",
    "            interface.current_thread_id = str(time.time())\n",
    "            return [], None\n",
    "\n",
    "        txt.submit(\n",
    "            interface.process_message,\n",
    "            inputs=[txt, image_display, chatbot],\n",
    "            outputs=[chatbot, image_display]\n",
    "        ).then(\n",
    "            lambda: \"\",\n",
    "            None,\n",
    "            [txt]\n",
    "        )\n",
    "\n",
    "        upload_button.upload(\n",
    "            lambda x: x,\n",
    "            inputs=upload_button,\n",
    "            outputs=image_display\n",
    "        )\n",
    "\n",
    "        clear_btn.click(clear_chat, outputs=[chatbot, image_display])\n",
    "        new_thread_btn.click(new_thread, outputs=[chatbot, image_display])\n",
    "\n",
    "    return demo\n",
    "\n",
    "demo = create_demo(agent)\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
