{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "from transformers import logging\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image\n",
    "\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "from medixar.agent import *\n",
    "from medixar.tools import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.set_verbosity_error()\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_tool = RadiologyReportGeneratorTool()\n",
    "organ_size_tool = OrganSizeMeasurementTool()\n",
    "\n",
    "print(type(report_tool))\n",
    "print(report_tool.name)\n",
    "print(type(organ_size_tool))\n",
    "print(organ_size_tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart medical assistant. Use the tools available to answer questions. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-2024-08-06\")\n",
    "abot = Agent(model, [report_tool, organ_size_tool], system=prompt)\n",
    "\n",
    "\n",
    "Image(abot.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the report of the radiology image `image.png`\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})\n",
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the volume of the heart in `image.png`?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})\n",
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################# LEGACY CODE #############################################################\n",
    "# web_search_tool = WebSearchTool()\n",
    "\n",
    "# agent = Agent(\n",
    "#     model=\"meta-llama/Llama-3.2-1B-Instruct\",\n",
    "#     tools={\"web_search\": web_search_tool},\n",
    "#     tools_json_path=\"medixar/docs/tools.json\",\n",
    "#     system_prompts_file=\"medixar/docs/system_prompts.txt\",\n",
    "#     system_prompt_type=\"MEDICAL_ASSISTANT\",\n",
    "#     device=\"auto\",\n",
    "#     torch_dtype=torch.float16,\n",
    "#     max_new_tokens=250,\n",
    "#     temperature=0.7,\n",
    "#     top_p=0.95\n",
    "# )\n",
    "\n",
    "# response = agent.generate(\"What is all you need? Respond using web search tool.\")\n",
    "# agent.messages\n",
    "# agent.generate(\"what was the answer to what is all you need?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "light",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
