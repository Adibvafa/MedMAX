{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. SFT or example database, prompt enhancing to make tool call better\\n2. show segmentation result overlay on the image\\n3. use ppx instead of cm2, support dicom\\n4. look agent benchmark + build benchmark\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "import warnings\n",
    "from typing import *\n",
    "import traceback\n",
    "\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from transformers import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from medmax.agent import *\n",
    "from medmax.tools import *\n",
    "from medmax.utils import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.set_verbosity_error()\n",
    "_ = load_dotenv()\n",
    "\n",
    "PROMPT_FILE = \"medmax/docs/system_prompts.txt\"\n",
    "SCRATCH_DIR = \"/scratch/ssd004/scratch/afallah\"\n",
    "\n",
    "\"\"\"\n",
    "1. SFT or example database, prompt enhancing to make tool call better\n",
    "2. show segmentation result overlay on the image\n",
    "3. use ppx instead of cm2, support dicom\n",
    "4. look agent benchmark + build benchmark\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U git+https://github.com/huggingface/transformers.git@88d960937c81a32bfb63356a2e8ecf7999619681\n",
    "# !pip install -U pydicom gdcm  pylibjpeg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bf7bb7f614484ba1bacfaa02b5b659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c1c21cbdaa4433807ab2dd2f413d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred while trying to fetch /scratch/ssd004/scratch/afallah/roentgen/unet: Error no file named diffusion_pytorch_model.safetensors found in directory /scratch/ssd004/scratch/afallah/roentgen/unet.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
      "An error occurred while trying to fetch /scratch/ssd004/scratch/afallah/roentgen/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /scratch/ssd004/scratch/afallah/roentgen/vae.\n",
      "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'medmax.tools.report_generation.ChestXRayReportGeneratorTool'>, Name: chest_xray_report_generator\n",
      "Type: <class 'medmax.tools.classification.ChestXRayClassifierTool'>, Name: chest_xray_classifier\n",
      "Type: <class 'medmax.tools.segmentation.ChestXRaySegmentationTool'>, Name: chest_xray_segmentation\n",
      "Type: <class 'medmax.tools.utils.ImageVisualizerTool'>, Name: image_visualizer\n",
      "Type: <class 'medmax.tools.grounding.XRayPhraseGroundingTool'>, Name: xray_phrase_grounding\n",
      "Type: <class 'medmax.tools.generation.ChestXRayGeneratorTool'>, Name: chest_xray_generator\n",
      "Type: <class 'medmax.tools.dicom.DicomProcessorTool'>, Name: dicom_processor\n"
     ]
    }
   ],
   "source": [
    "report_tool = ChestXRayReportGeneratorTool()\n",
    "xray_classification_tool = ChestXRayClassifierTool()\n",
    "# medical_visual_qa_tool = MedicalVisualQATool()\n",
    "segmentation_tool = ChestXRaySegmentationTool()\n",
    "image_visualizer_tool = ImageVisualizerTool()\n",
    "grounding_tool = XRayPhraseGroundingTool(cache_dir=SCRATCH_DIR, temp_dir=\"temp\")\n",
    "generation_tool = ChestXRayGeneratorTool(model_path=f\"{SCRATCH_DIR}/roentgen\", temp_dir=\"temp\")\n",
    "dicom_tool = DicomProcessorTool(temp_dir=\"temp\")\n",
    "\n",
    "print(f\"Type: {type(report_tool)}, Name: {report_tool.name}\")\n",
    "print(f\"Type: {type(xray_classification_tool)}, Name: {xray_classification_tool.name}\")\n",
    "# print(f\"Type: {type(medical_visual_qa_tool)}, Name: {medical_visual_qa_tool.name}\")\n",
    "print(f\"Type: {type(segmentation_tool)}, Name: {segmentation_tool.name}\")\n",
    "print(f\"Type: {type(image_visualizer_tool)}, Name: {image_visualizer_tool.name}\")\n",
    "print(f\"Type: {type(grounding_tool)}, Name: {grounding_tool.name}\")\n",
    "print(f\"Type: {type(generation_tool)}, Name: {generation_tool.name}\")\n",
    "print(f\"Type: {type(dicom_tool)}, Name: {dicom_tool.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = load_prompts_from_file(PROMPT_FILE)\n",
    "prompt = prompts[\"MEDICAL_ASSISTANT\"]\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "model = ChatOpenAI(model=\"gpt-4o-2024-08-06\", temperature=0, top_p=0.95)\n",
    "agent = Agent(\n",
    "    model, \n",
    "    tools=[xray_classification_tool,\n",
    "           report_tool, \n",
    "           segmentation_tool, \n",
    "           image_visualizer_tool, \n",
    "           grounding_tool, \n",
    "           generation_tool],\n",
    "    log_tools=True,\n",
    "    log_dir=\"logs\",\n",
    "    system_prompt=prompt, \n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Image(agent.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [HumanMessage(content=\"Does the image `demo/chest/pneumonia4.jpg` show pneumonia?\")]\n",
    "# messages = [HumanMessage(content=\"Provide a radiology report for the given image `demo/chest/pneumonia2.jpg`.\")]\n",
    "# messages = [HumanMessage(content=\"Descibe the given image.\")]\n",
    "# messages = [HumanMessage(content=\"What was the first question I asked?\")]\n",
    "# messages = [HumanMessage(content=\"What is the probability of pneumonia in the image `demo/chest/normal1.jpg`?\")]\n",
    "# messages = [HumanMessage(content=\"Does the patient with chest xray given here need to go see doctor? `demo/chest/normal1.jpg`\")]\n",
    "# messages = [HumanMessage(content=\"What is the size of heart?\")]\n",
    "messages = [HumanMessage(content=\"Ground pleural effusion in the image `demo/chest/effusion1.png`.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in agent.workflow.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': \"Unable to decompress 'JPEG Lossless, Non-Hierarchical, First-Order Prediction (Process 14 [Selection Value 1])' pixel data because all plugins are missing dependencies:\\n\\tgdcm - requires gdcm>=3.0.10\\n\\tpylibjpeg - requires pylibjpeg>=2.0 and pylibjpeg-libjpeg>=2.1\"}\n"
     ]
    }
   ],
   "source": [
    "output, _ = dicom_tool._run(\"temp/upload_1732291135.dcm\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "* Running on public URL: https://4d8bea6d35b828e066.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4d8bea6d35b828e066.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DICOM file: temp/upload_1732291334.dcm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "import time\n",
    "import shutil\n",
    "from typing import List, Optional, Tuple\n",
    "from gradio import ChatMessage\n",
    "\n",
    "class ChatInterface:\n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "        self.upload_dir = Path(\"temp\")\n",
    "        self.upload_dir.mkdir(exist_ok=True)\n",
    "        self.current_thread_id = None\n",
    "        self.uploaded_image = None\n",
    "        self.current_display_image = None\n",
    "        self.dicom_tool = DicomProcessorTool(temp_dir=\"temp\")\n",
    "\n",
    "    def handle_upload(self, file_path: str) -> Tuple[str, str]:\n",
    "        \"\"\"\n",
    "        Handles file uploads, converting DICOM to PNG for display if needed\n",
    "        Returns: Tuple[display_path, prompt_path]\n",
    "        \"\"\"\n",
    "        if not file_path:\n",
    "            return None, None\n",
    "            \n",
    "        source = Path(file_path)\n",
    "        timestamp = int(time.time())\n",
    "        prompt_path = self.upload_dir / f\"upload_{timestamp}{source.suffix}\"\n",
    "        shutil.copy2(source, prompt_path)\n",
    "        \n",
    "        # If DICOM file, convert to PNG for display\n",
    "        if source.suffix.lower() == '.dcm':\n",
    "            print(f\"Processing DICOM file: {prompt_path}\")\n",
    "            output, _ = self.dicom_tool._run(str(prompt_path))\n",
    "            return output['image_path'], str(prompt_path)\n",
    "        \n",
    "        return str(prompt_path), str(prompt_path)\n",
    "\n",
    "    async def process_message(self, \n",
    "                            message: str, \n",
    "                            image: Optional[str], \n",
    "                            chat_history: List[ChatMessage]) -> List[ChatMessage]:\n",
    "        chat_history = chat_history or []\n",
    "        \n",
    "        # Handle new image upload\n",
    "        if image and (not self.current_display_image or image != self.current_display_image):\n",
    "            display_path, prompt_path = self.handle_upload(image)\n",
    "            self.current_display_image = display_path\n",
    "            self.uploaded_image = prompt_path\n",
    "            \n",
    "        # Append image path to message if exists\n",
    "        if self.uploaded_image:\n",
    "            message = f\"{message} `{self.uploaded_image}`\"\n",
    "        \n",
    "        # Initialize thread if needed\n",
    "        if not self.current_thread_id:\n",
    "            self.current_thread_id = str(time.time())\n",
    "        \n",
    "        # Add user message to history\n",
    "        chat_history.append(ChatMessage(role=\"user\", content=message))\n",
    "        yield chat_history, self.current_display_image\n",
    "        \n",
    "        try:\n",
    "            for event in self.agent.workflow.stream(\n",
    "                {\"messages\": [{\"role\": \"user\", \"content\": message}]},\n",
    "                {\"configurable\": {\"thread_id\": self.current_thread_id}}\n",
    "            ):\n",
    "                if isinstance(event, dict):\n",
    "                    if 'process' in event:\n",
    "                        content = event['process']['messages'][-1].content\n",
    "                        if content:\n",
    "                            chat_history.append(ChatMessage(\n",
    "                                role=\"assistant\",\n",
    "                                content=content\n",
    "                            ))\n",
    "                            yield chat_history, self.current_display_image\n",
    "\n",
    "                    elif 'execute' in event:\n",
    "                        for message in event['execute']['messages']:\n",
    "                            tool_name = message.name\n",
    "                            tool_result = eval(message.content)[0]\n",
    "                            \n",
    "                            if tool_name == \"image_visualizer\":\n",
    "                                self.current_display_image = message.args['image_path']\n",
    "                            \n",
    "                            if tool_result:\n",
    "                                formatted_result = ' '.join(line.strip() for line in str(tool_result).splitlines()).strip()\n",
    "                                chat_history.append(ChatMessage(\n",
    "                                    role=\"assistant\",\n",
    "                                    content=formatted_result,\n",
    "                                    metadata={\"title\": f\"🔧 Using tool: {tool_name}\"},\n",
    "                                ))\n",
    "                                yield chat_history, self.current_display_image\n",
    "                            \n",
    "        except Exception as e:\n",
    "            chat_history.append(ChatMessage(\n",
    "                role=\"assistant\",\n",
    "                content=f\"❌ Error: {str(e)}\",\n",
    "                metadata={\"title\": \"Error\"}\n",
    "            ))\n",
    "            yield chat_history, self.current_display_image\n",
    "\n",
    "def create_demo(agent):\n",
    "    interface = ChatInterface(agent)\n",
    "    \n",
    "    with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"\"\"\n",
    "            # 🏥 MedMAX\n",
    "            Multimodal Medical Agent for Chest X-rays\n",
    "            \"\"\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=3):\n",
    "                    chatbot = gr.Chatbot(\n",
    "                        [],\n",
    "                        height=800,\n",
    "                        container=True,\n",
    "                        show_label=True,\n",
    "                        elem_classes=\"chat-box\",\n",
    "                        type=\"messages\",\n",
    "                        label=\"Agent\",\n",
    "                        avatar_images=(None, \"https://em-content.zobj.net/source/twitter/53/robot-face_1f916.png\")\n",
    "                    )\n",
    "                    with gr.Row():\n",
    "                        with gr.Column(scale=3):\n",
    "                            txt = gr.Textbox(\n",
    "                                show_label=False,\n",
    "                                placeholder=\"Ask about the X-ray...\",\n",
    "                                container=False\n",
    "                            )\n",
    "                            \n",
    "                with gr.Column(scale=3):\n",
    "                    image_display = gr.Image(\n",
    "                        label=\"Image\",\n",
    "                        type=\"filepath\",\n",
    "                        height=700,\n",
    "                        container=True\n",
    "                    )\n",
    "                    with gr.Row():\n",
    "                        upload_button = gr.UploadButton(\n",
    "                            \"📎 Upload X-Ray\",\n",
    "                            file_types=[\"image\"],\n",
    "                        )\n",
    "                        dicom_upload = gr.UploadButton(\n",
    "                            \"📄 Upload DICOM\",\n",
    "                            file_types=[\"file\"],\n",
    "                        )\n",
    "                    with gr.Row():\n",
    "                        clear_btn = gr.Button(\"Clear Chat\")\n",
    "                        new_thread_btn = gr.Button(\"New Thread\")\n",
    "\n",
    "        # Event handlers\n",
    "        def clear_chat():\n",
    "            interface.uploaded_image = None\n",
    "            interface.current_display_image = None\n",
    "            return [], None\n",
    "\n",
    "        def new_thread():\n",
    "            interface.current_thread_id = str(time.time())\n",
    "            interface.uploaded_image = None\n",
    "            interface.current_display_image = None\n",
    "            return [], None\n",
    "\n",
    "        def handle_file_upload(file):\n",
    "            display_path, _ = interface.handle_upload(file.name)\n",
    "            return display_path\n",
    "\n",
    "        txt.submit(\n",
    "            interface.process_message,\n",
    "            inputs=[txt, image_display, chatbot],\n",
    "            outputs=[chatbot, image_display]\n",
    "        ).then(\n",
    "            lambda: \"\",\n",
    "            None,\n",
    "            [txt]\n",
    "        )\n",
    "\n",
    "        upload_button.upload(\n",
    "            handle_file_upload,\n",
    "            inputs=upload_button,\n",
    "            outputs=image_display\n",
    "        )\n",
    "        \n",
    "        dicom_upload.upload(\n",
    "            handle_file_upload,\n",
    "            inputs=dicom_upload,\n",
    "            outputs=image_display\n",
    "        )\n",
    "\n",
    "        clear_btn.click(clear_chat, outputs=[chatbot, image_display])\n",
    "        new_thread_btn.click(new_thread, outputs=[chatbot, image_display])\n",
    "\n",
    "    return demo\n",
    "\n",
    "demo = create_demo(agent)\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
